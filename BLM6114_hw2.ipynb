{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyupdalan/BLM6114-hw2/blob/main/BLM6114_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEAGUtHj6RE"
      },
      "source": [
        "# Hesaplamalı Anlambilim Dersi 2.Ödevi\n",
        "Konusu: Sınıflandırma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs2EnOnPlJWp"
      },
      "source": [
        "## Package installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2NOZB9XlTOq"
      },
      "outputs": [],
      "source": [
        "!pip install datasets torch scikit-learn transformers # uncomment if necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTt3wNx_j-Fl"
      },
      "source": [
        "### Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWch5zKZj04-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFH2nOkkFON"
      },
      "source": [
        "## Dataset preperations\n",
        "https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE\n",
        "\n",
        "sst2 için eğitim kümesini 60K-->5K, test kümesini 9K-->1K düşürerek kullanınız.\n",
        "\n",
        "> TrSST-2 The Stanford Sentiment Treebank is a sentiment analysis dataset includes sentences from movie reviews, annotated by human annotators. The task is to predict the sentiment of a given sentence. Our dataset is compiled from movie review websites BeyazPerde.com and Sinefil.com, both reviews and sentiment ratings are compiled from those websites. Here we offer a binary classification task to be compatible with the original GLUE task, however we offer a 10-way classification challenge in this dataset's standalone HuggingFace repo.\n",
        "\n",
        "cola için eğitim kümesini 8K-->5K, test kümesini değiştirmeden kullanınız.\n",
        "\n",
        "> TrCOLA The original Corpus of Linguistic Acceptability consists of sentences compiled from English literature textbooks. The task is to determine if the sentences are grammatically correct and acceptable sentences. Our corpus is also compiled from Turkish linguistic textbooks and include morphological, syntactic and semantic violations. This dataset also has a standalone repo on HuggingFace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezw0Cg0gB2Z4"
      },
      "outputs": [],
      "source": [
        "# SST2\n",
        "sst2 = load_dataset(\"turkish-nlp-suite/TrGLUE\", \"sst2\")\n",
        "sst2_train = sst2['train'].shuffle(seed=42).select(range(5000))  # Eğitim: 60K -> 5K\n",
        "sst2_test = sst2['test'].shuffle(seed=42).select(range(1000))  # Test: 9K -> 1K\n",
        "\n",
        "# CoLA\n",
        "cola = load_dataset(\"turkish-nlp-suite/TrGLUE\", \"cola\")\n",
        "cola_train = cola['train'].shuffle(seed=42).select(range(5000))  # Eğitim: 5K\n",
        "cola_test = cola['test']  # Test: Tüm test kümesi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaCP8eB3pquD"
      },
      "source": [
        "## Check imported data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjZxB6LKpqU1"
      },
      "outputs": [],
      "source": [
        "sst_train_len = len(sst2_train)\n",
        "sst_test_len = len(sst2_test)\n",
        "cola_train_len = len(cola_train)\n",
        "cola_test_len = len(cola_test)\n",
        "\n",
        "print(f\"SST2 eğitim kümesi uzunluğu: {sst_train_len}\")\n",
        "print(f\"SST2 test kümesi uzunluğu: {sst_test_len}\")\n",
        "print(f\"CoLA eğitim kümesi uzunluğu: {cola_train_len}\")\n",
        "print(f\"CoLA test kümesi uzunluğu: {cola_test_len}\")\n",
        "\n",
        "# sst2_train verisinin ilk 10 satırını yazdır\n",
        "print(\"sst2_train:\")\n",
        "for i in range(10):\n",
        "    print(sst2_train[i])\n",
        "\n",
        "# sst2_test verisinin ilk 10 satırını yazdır\n",
        "print(\"\\nsst2_test:\")\n",
        "for i in range(10):\n",
        "    print(sst2_test[i])\n",
        "\n",
        "# cola_train verisinin ilk 10 satırını yazdır\n",
        "print(\"\\ncola_train:\")\n",
        "for i in range(10):\n",
        "    print(cola_train[i])\n",
        "\n",
        "# cola_test verisinin ilk 10 satırını yazdır\n",
        "print(\"\\ncola_test:\")\n",
        "for i in range(10):\n",
        "    print(cola_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DxcVCVGuPcN"
      },
      "source": [
        "## Model installments\n",
        "\n",
        "1. https://huggingface.co/ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\n",
        "2. https://huggingface.co/google/gemma-2-9b-it\n",
        "3. https://huggingface.co/Trendyol/Llama-3-Trendyol-LLM-8b-chat-v2.0\n",
        "4. https://huggingface.co/TURKCELL/Turkcell-LLM-7b-v1\n",
        "5. https://huggingface.co/WiroAI/wiroai-turkish-llm-9b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCPXD8byuTEP"
      },
      "outputs": [],
      "source": [
        "def generate_llm (model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    return llm\n",
        "\n",
        "# Modelleri yükleme\n",
        "models = {\n",
        "    \"cosmos_dpo\": generate_llm(\"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\"),\n",
        "    \"gemma2_9b\": generate_llm(\"Metin/Gemma-2-9b-it-TR-DPO-V1\"),\n",
        "    \"trendyol_llm\": generate_llm(\"Trendyol/Trendyol-LLM-8b-chat-v2.0\"),\n",
        "    \"turkcell_llm\":generate_llm(\"TURKCELL/Turkcell-LLM-7b-v1\"),\n",
        "    \"wiroai_llm\": generate_llm(\"WiroAI/wiroai-turkish-llm-9b\"),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompts_with_examples_sst2(sentence, shot_count):\n",
        "  prompt = f'Cümle: \"{sentence}\"\\nBu cümledeki duygu olumlu mu? Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\\n'\n",
        "  selected_examples = sst2_train.shuffle(seed=42).select(range(shot_count))\n",
        "  examples = \"\"\n",
        "  for i in range(shot_count):\n",
        "    cevap = \"\"\n",
        "    if(selected_examples[\"label\"][i] == 1):\n",
        "      cevap = \"Bu cümledeki duygu olumludur\"\n",
        "    else:\n",
        "      cevap = \"Bu cümledeki duygu olumsuzdur\"\n",
        "    examples += f'Cümle: \"{selected_examples[\"sentence\"][i]}\"\\nCevap: {cevap}\\n'\n",
        "\n",
        "  if (examples != \"\"):\n",
        "    examples += \"Yukarıdaki cümleleri ve cevaplarını değerlendir.\\n\"\n",
        "\n",
        "  return f\"{examples}{prompt}\"\n",
        "\n",
        "def build_prompts_with_examples_cola(sentence, shot_count):\n",
        "  prompt = f'Cümle: \"{sentence}\"\\nBu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\\n'\n",
        "  selected_examples = cola_train.shuffle(seed=42).select(range(shot_count))\n",
        "  examples = \"\"\n",
        "  for i in range(shot_count):\n",
        "    cevap = \"\"\n",
        "    if(selected_examples[\"label\"][i] == 1):\n",
        "      cevap = \"Bu cümle kurallara uygundur\"\n",
        "    else:\n",
        "      cevap = \"Bu cümle kurallara uygun değildir\"\n",
        "    examples += f'Cümle: \"{selected_examples[\"sentence\"][i]}\"\\nCevap: {cevap}\\n'\n",
        "\n",
        "  if (examples != \"\"):\n",
        "    examples += \"Yukarıdaki cümleleri ve cevaplarını değerlendir.\\n\"\n",
        "\n",
        "  return f\"{examples}{prompt}\"\n",
        "\n",
        "\n",
        "def run_prompt(prompt, model_name, max_new_tokens=150):\n",
        "  print(f\"Model: {model_name}\")\n",
        "  print(f\"Prompt: {prompt}\")\n",
        "  outputs = models[model_name](prompt, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "  generated = outputs[0]['generated_text'][len(prompt):].lower().strip()\n",
        "  return generated\n",
        "\n",
        "def run_bulk_prompt(prompts, model_name, max_new_tokens=150):\n",
        "  outputs = models[model_name](prompts, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "  generated_outputs = []\n",
        "  for output in outputs:\n",
        "    generated = output[0]['generated_text'][len(prompts[outputs.index(output)]):].lower().strip()  # İstem uzunluğunu çıkar\n",
        "    generated_outputs.append(generated)\n",
        "\n",
        "  return generated_outputs\n",
        "\n",
        "def bulk_predict_for_few_shot_sst2(sentences, shot_count, model_name):\n",
        "  prompts = [build_prompts_with_examples_sst2(sentence, shot_count) for sentence in sentences]\n",
        "  outputs = run_bulk_prompt(prompts, model_name)\n",
        "  pred_labels = []\n",
        "  for i, output in enumerate(outputs):\n",
        "    if \"evet\" in output:\n",
        "      pred_labels.append(1)\n",
        "    elif \"hayır\" in output:\n",
        "      pred_labels.append(0)\n",
        "    else:\n",
        "      pred_labels.append(-1)\n",
        "  return pred_labels\n",
        "\n",
        "def bulk_predict_for_few_shot_cola(sentences, shot_count, model_name):\n",
        "  prompts = [build_prompts_with_examples_cola(sentence, shot_count) for sentence in sentences]\n",
        "  outputs = run_bulk_prompt(prompts, model_name)\n",
        "  pred_labels = []\n",
        "  for i, output in enumerate(outputs):\n",
        "    if \"evet\" in output:\n",
        "      pred_labels.append(1)\n",
        "    elif \"hayır\" in output:\n",
        "      pred_labels.append(0)\n",
        "    else:\n",
        "      pred_labels.append(-1)\n",
        "  return pred_labels"
      ],
      "metadata": {
        "id": "hDk3Olcp2pmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sst2_test[\"sentence\"][:5])\n",
        "print(sst2_test[\"label\"][:5])\n",
        "\n",
        "print(sst2_test.select(range(3))[\"sentence\"])"
      ],
      "metadata": {
        "id": "lah514XlMRAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_prompt(build_prompts_with_examples_cola(cola_test[\"sentence\"][0],0), \"cosmos_dpo\"))"
      ],
      "metadata": {
        "id": "r7b6OD2k0WF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 0))\n",
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 3))\n",
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 5))\n",
        "\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 0))\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 3))\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 5))"
      ],
      "metadata": {
        "id": "ZHX1Myulnc57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = 10\n",
        "print(f\"Started for {sample_count} samples\")\n",
        "\n",
        "def run_analyse_for_sst2():\n",
        "  actual_labels_sst2 = sst2_test[\"label\"][:sample_count]\n",
        "  actual_labels_cola = cola_test[\"label\"][:sample_count]\n",
        "  print(f\"True Labels - sst-2: {actual_labels_sst2}\")\n",
        "  print(f\"True Labels - cola: {actual_labels_cola}\")\n",
        "\n",
        "  all_results = []\n",
        "\n",
        "  for model in models:\n",
        "    print(f\"Model: {model}\")\n",
        "\n",
        "    for shot in [0, 3, 5]:\n",
        "      print(f\"Shot: {shot}\")\n",
        "      print(f\"SST-2\")\n",
        "      predicted_labels_sst2 = bulk_predict_for_few_shot_sst2(sst2_test[\"sentence\"][:sample_count], shot_count=shot, model_name=model)\n",
        "\n",
        "      accuracy_sst2 = accuracy_score(actual_labels_sst2, predicted_labels_sst2)\n",
        "      f1_sst2 = f1_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "      precision_sst2 = precision_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "      recall_sst2 = recall_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "\n",
        "      all_results.append({\n",
        "        \"model\": model,\n",
        "        \"task\": \"SST-2\",\n",
        "        \"shot\": shot,\n",
        "        \"accuracy\": accuracy_sst2,\n",
        "        \"f1\": f1_sst2,\n",
        "        \"precision\": precision_sst2,\n",
        "        \"recall\": recall_sst2\n",
        "      })\n",
        "\n",
        "      print(f\"CoLA\")\n",
        "      predicted_labels_cola = bulk_predict_for_few_shot_cola(cola_test[\"sentence\"][:sample_count], shot_count=shot, model_name=model)\n",
        "\n",
        "      accuracy_cola = accuracy_score(actual_labels_cola, predicted_labels_cola)\n",
        "      f1_cola = f1_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "      precision_cola = precision_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "      recall_cola = recall_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "\n",
        "      all_results.append({\n",
        "        \"model\": model,\n",
        "        \"task\": \"CoLA\",\n",
        "        \"shot\": shot,\n",
        "        \"accuracy\": accuracy_cola,\n",
        "        \"f1\": f1_cola,\n",
        "        \"precision\": precision_cola,\n",
        "        \"recall\": recall_cola\n",
        "      })\n",
        "\n",
        "  return all_results\n",
        "\n",
        "\n",
        "results = run_analyse_for_sst2()\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nTüm sonuçlar:\")\n",
        "print(results_df)\n",
        "\n",
        "# Görselleştirme: Task ve shot sayısına göre doğruluk\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='model', y='accuracy', hue='shot',\n",
        "            data=results_df, palette='viridis',\n",
        "            dodge=True, ci=None)\n",
        "plt.title('LLM Modellerinin Görevlere Göre Doğruluk Performansı')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Shot Sayısı')\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_accuracy_by_shot.png')\n",
        "plt.show()\n",
        "\n",
        "# Task ve modele göre doğruluk karşılaştırması\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='task', y='accuracy', hue='model',\n",
        "            data=results_df, palette='Set2',\n",
        "            dodge=True, ci=None)\n",
        "plt.title('Görevlere Göre Model Doğruluk Karşılaştırması')\n",
        "plt.xlabel('Görev')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend(title='Model')\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_accuracy_by_model.png')\n",
        "plt.show()\n",
        "\n",
        "# Shot sayısının performans üzerindeki etkisi\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "for i, task in enumerate(['CoLA', 'SST-2']):\n",
        "    task_df = results_df[results_df['task'] == task]\n",
        "    sns.lineplot(x='shot', y='accuracy', hue='model',\n",
        "                 data=task_df, palette='Set1',\n",
        "                 markers=True, dashes=False, ax=axes[i])\n",
        "    axes[i].set_title(f'{task} Görevinde Shot Sayısının Etkisi')\n",
        "    axes[i].set_xlabel('Shot Sayısı')\n",
        "    axes[i].set_ylabel('Doğruluk')\n",
        "    axes[i].grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('shot_effect_on_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# 9. Sonuçların özeti\n",
        "# =============\n",
        "\n",
        "print(\"\\n=== ÖZET RAPOR ===\")\n",
        "\n",
        "# Görev ve model bazında en iyi performanslar\n",
        "for task in ['CoLA', 'SST-2']:\n",
        "    task_df = results_df[results_df['task'] == task]\n",
        "    best_model_idx = task_df['accuracy'].idxmax()\n",
        "    best_model = task_df.loc[best_model_idx]\n",
        "\n",
        "    print(f\"\\n{task} görevinde en iyi performans:\")\n",
        "    print(f\"Model: {best_model['model']}\")\n",
        "    print(f\"Shot Sayısı: {best_model['shot']}\")\n",
        "    print(f\"Doğruluk: {best_model['accuracy']:.4f}\")\n",
        "    print(f\"F1 Skor: {best_model['f1']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WM-0EvMLsJSE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO0PtpfrlWVGSQXJWyoWUqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}