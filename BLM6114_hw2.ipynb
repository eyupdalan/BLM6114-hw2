{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyupdalan/BLM6114-hw2/blob/main/BLM6114_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEAGUtHj6RE"
      },
      "source": [
        "# Hesaplamalı Anlambilim Dersi 2.Ödevi\n",
        "Konusu: Sınıflandırma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs2EnOnPlJWp"
      },
      "source": [
        "## Package installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2NOZB9XlTOq",
        "outputId": "12992bfb-60bc-4cef-d99a-6cb6bc60f9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch scikit-learn transformers # uncomment if necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTt3wNx_j-Fl"
      },
      "source": [
        "### Necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uWch5zKZj04-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFH2nOkkFON"
      },
      "source": [
        "## Dataset preperations\n",
        "https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE\n",
        "\n",
        "sst2 için eğitim kümesini 60K-->5K, test kümesini 9K-->1K düşürerek kullanınız.\n",
        "\n",
        "> TrSST-2 The Stanford Sentiment Treebank is a sentiment analysis dataset includes sentences from movie reviews, annotated by human annotators. The task is to predict the sentiment of a given sentence. Our dataset is compiled from movie review websites BeyazPerde.com and Sinefil.com, both reviews and sentiment ratings are compiled from those websites. Here we offer a binary classification task to be compatible with the original GLUE task, however we offer a 10-way classification challenge in this dataset's standalone HuggingFace repo.\n",
        "\n",
        "cola için eğitim kümesini 8K-->5K, test kümesini değiştirmeden kullanınız.\n",
        "\n",
        "> TrCOLA The original Corpus of Linguistic Acceptability consists of sentences compiled from English literature textbooks. The task is to determine if the sentences are grammatically correct and acceptable sentences. Our corpus is also compiled from Turkish linguistic textbooks and include morphological, syntactic and semantic violations. This dataset also has a standalone repo on HuggingFace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezw0Cg0gB2Z4",
        "outputId": "78f2d8ba-614e-4b10-f54a-b875719d05fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# SST2\n",
        "sst2 = load_dataset(\"turkish-nlp-suite/TrGLUE\", \"sst2\")\n",
        "sst2_train = sst2['train'].shuffle(seed=42).select(range(5000))  # Eğitim: 60K -> 5K\n",
        "sst2_test = sst2['test'].shuffle(seed=42).select(range(1000))  # Test: 9K -> 1K\n",
        "\n",
        "# CoLA\n",
        "cola = load_dataset(\"turkish-nlp-suite/TrGLUE\", \"cola\")\n",
        "cola_train = cola['train'].shuffle(seed=42).select(range(5000))  # Eğitim: 5K\n",
        "cola_test = cola['test']  # Test: Tüm test kümesi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaCP8eB3pquD"
      },
      "source": [
        "## Check imported data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjZxB6LKpqU1",
        "outputId": "ee8d43a2-e51a-491c-f2ee-ab6a2afc3796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST2 eğitim kümesi uzunluğu: 5000\n",
            "SST2 test kümesi uzunluğu: 1000\n",
            "CoLA eğitim kümesi uzunluğu: 5000\n",
            "CoLA test kümesi uzunluğu: 1000\n",
            "sst2_train:\n",
            "{'sentence': 'film başladığında bir müddet izlemesem mi acaba, sıkıcı bir filme benziyor diye düşündüm. Ancak ilerledikçe iyi ki devam etmişim dedim. Farklı ve gerçekten iyi bir film. İyi seyirler..', 'label': 1}\n",
            "{'sentence': 'Film gerçek hayata göndermeler yapıyor. Filmi çok başarılı buldum gerçekten ender güzel yapımlardan. Her sahnesi özenle hazırlanmış. Oyunculuklar, replikler harika, fazla söze gerek yok mutlaka izlenmesi gereken bir yapım, sinema severlere duyrulur :)', 'label': 1}\n",
            "{'sentence': 'harika bir animasyon. çok eğlenceli. tıpkı birincisi gibi.', 'label': 1}\n",
            "{'sentence': \"Ümit ünal filmlerini genelde beğenirim bu filmde keyifle izlediğim filmlerden hele ki evdeki ilk ayaküstü sorgulama sahnesi çok bizden kara mizah ama gerilimi daha çok mizahı daha az olsaydı diye de ummadım değil... Demet Evgar'ın katmanlı karakterini izlemek her performası gibi yine mest ettirdi. Kendisinin oyunculuğuna hayran çok kişi olduğunu yorumlarda bir kez daha fark edince belirtmek isterim 39 basamak tiyatro oyununu kaçırmamalısınız ;)\", 'label': 1}\n",
            "{'sentence': 'Birşeyler Yapmaya çalışmış lakin Olmamış. hızlı ve Öfkeli izleyen insanlar için bu film yemez. Yine de emeğe saygı.', 'label': 0}\n",
            "{'sentence': 'gayet eğlenceli ve sıcak bir film. sadece birkaç gereksiz küfür sahnesi var. kurguda, planların bağlanmasında bence bazı sorunlar vardı, filmin hızını azaltan, onun haricinde beğendim. oyunculuklar da çok doğal ve iyi.', 'label': 1}\n",
            "{'sentence': 'böylesini izlemedim dedirtmez ama tatlı bir kendini iyi hisset filmi :) bir IUsever olarak izledim.', 'label': 1}\n",
            "{'sentence': 'Bir kadının hayata karşı tek başına verdiği büyük mücadeleyi konu alan filmde Charlize Theron oyunculuğuyla ön plana çıkmayı başarıyor.. Tüm baskılara rağmen, savaşından vazgeçmeyen bir kadının hikayesi...', 'label': 1}\n",
            "{'sentence': 'Brad Pitt ve Morgan Freeman oynadığı için düşündüğüm gibi oyunculukları her zamanki gibi kusursuzdu. Senaryo da 1995 yapım olmasına rağmen gayet başarılı. Ben bir kusur bulamadım filme, imdb den aldığı puanı sonuna kadar haketmiş. Bugüne kadar nasıl izlemedim ona hala üzülmekteyim.', 'label': 1}\n",
            "{'sentence': 'ikinci serinin en iyi filmi diyebileceğim birçok sorunun cevabını bulabileceğiniz bir yapım 8/10', 'label': 1}\n",
            "\n",
            "sst2_test:\n",
            "{'sentence': 'Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!', 'label': 0}\n",
            "{'sentence': 'İnsanın başına hiç beklemediği şeyler gelebilir gibi kısa ve klişe bir temayı filme biraz olsun anlam katmak için mi yaptılar ne...', 'label': 0}\n",
            "{'sentence': \"Etkileyici bir kişilik Desmond Doss. Kesinlikle tarihe geçen bir hikayesi var. Mel Gibson bu gibi kahramanlık hikayelerini her zaman sevmiştir. Hacksaw Ridge&te de iyi iş çıkardığını söyleyebiliriz. Aslında izlerken pek çok mantık hatası var gibi gelse de, sonradan kısaca göz attığım tarihi gerçeklerde meğer olayların büyük oranda bu şekilde gerçekleşmiş olduğunu okudum. Uzun yıllar akılda kalıcı bir film mi? Pek sanmıyorum. Çünkü nedense o Er Ryan'ı Kurtarmak gibi bir hava yok maalesef filmde. Başlangıç bölümlerini biraz daha kısaltabilirlerdi. Garfield'ın oyunculuğu başarılı ancak kendisine ödül getirmeye yeterli mi, sanmıyorum. Filmin ikinci yarısı katıksız bir savaş filmi havasındayken, ilk yarısında pek bir hareket yok. Bunun bilinciyle izlemenizi öneririm.\", 'label': 1}\n",
            "{'sentence': \"&Tinker Tailor Soldier Spy'ın yönetmeni Tomas Alfredson'ın yönettiği ve Martin Scorsese'nin yapımcılığını üstlendiği The Snowman'ın başrolünde son zamanların başarılı oyuncularından Michael Fassbender, Rebecca Ferguson ve J.K. Simmons var.& Başlı başına bu cümle ile ortaya hiç olmazsa ortalamanın üzerinde bir iş çıkması gerekir, değil mi? Ama maalesef The Snowman, bu tabirin yakınından bile geçemiyor. Hatta ortaya bu yılın kaçırılmış en büyük fırsatı çıkmış diyebilirim. İlk önce konuya değinelim. Filmin fragmanına göre The Snowman'in konusu şu: Son zamanlarda ortaya çıkıp insanları vahşetli bir şekilde öldüren Kardan Adam Katili'ni yakalamak için ünlü detektif Harry Hole ile meslektaşı Katrine Bratt, kendilerini oldukça tehlikeli bir gizemin içerisine bulurlar. Ve bu ikili katili bulmaya yaklaştıkça cinayetler artacak, durum ise içinden çıkılamaz bir hal alacaktır.& Öncelikle fragmanının anlatmaya çalıştığı konunun filmle alakasızlığını bırakın bir yana, bu fragmanın seyirciyi en çok yanıltacak yönü, The Snowman'i aşırı vahşetli bir korku filmi olarak gösteriyor oluşu herhalde. Çünkü film başlamadan önce arkamda oturan çiftlerden bir tanesi Eğer film fazla şiddetli gelecekse salondan hemen ayrılabiliriz gibi bir laf etti. Dürüst olmam gerekirse, ben de bu filmin ne kadar rahatsız edici olacağını bilmiyordum. Ama ortaya çıkan sonuçtan oldukça memnun kaldım çünkü bu film sayesinde 2 saat boyunca mışıl mışıl uyudum. Ama şaka bir yana The Snowman, muhtemelen şu an vizyonda oynayan en sıkıcı film sayılır. Neden mi? Çünkü bu filmde hiçbir şey yaşanmıyor da ondan! Aslında her ne kadar The Snowman'in ilk yarısı, tıpkı filmin geri kalanı gibi sadece diyaloglardan ibaret olsa da sürekli kendi kendime; Meraklanma, cevaplar yakında gelecek, yaşananlar en sonunda bir yere bağlanacak.& deyip durdum. Sonra film ikinci yarıya girdi. Ve film bittiğinde süre boyunca sorulan soruların hiçbirine cevap alamadığımı fark ettim, katilin kim olduğu dışında. Bu film Søren Sveistrup, Peter Straughan ile Hossein Amini gibi kuvvetli senaristler tarafından yazılmış. Fakat film stüdyosunun sürekli içeriğe karışması, filmin %15'lik bir diliminin çekilememesi, yönetmen ile senaryonun son anda değişikliğe uğraması ve hatta bir sürü sahnenin yeniden çekilmesiyle The Snowman, görüleceği üzere, büyük bir dağınıklıktan ibaret olmuş. Ve işin asıl acı veren tarafı bu filmde o kadar çok yetenek var ki, film bunların hiçbirini kullanmayı beceremiyor. Bu filmin de yaşadığı en büyük sıkıntı burada aslında. The Snowman harika manzaralara, başarılı bir yönetmene, güçlü oyunculuklara ve bazı yaratıcı fikirlere sahip olsa da ortaya çıkan sonuç o kadar dağınık olmuş ki, çıkan sonuç tek kelimeyle izlenemez bir hal almış. Aylar sonra bu film ev sinemasına gelip The Snowman'in DVD'sini rafta gördüğünüzde içinizden büyük ihtimalle şöyle bir düşünce geçecek: Vay be, oyuncu kadrosuna ve yönetmene bak hele! Gizem filmlerini sevdiğim için muhtemelen bu filmi de severim, bence eleştirmenler olayı fazla abartmış.& Ama filmi izlemiş birisi olarak size diyorum ki, bu filmi sakın izlemeyin. Biliyorum, film ekibi ile içerik hakkında o kadar yerden yere vurulacak bir şey yok. Hatta bu yıl izlediğim en kötü filmler arasında ilk 10'a gireceğinden bile şüpheliyim. Ama bu filmi öyle bir kırpmışlar ki, çıkan sonuç neresinden tutsan elinde kalıyor. Bir gizem filmi için fazla durağan, bir korku filmi için fazla kansız, sırf oyuncuların döktürmesini görmek isteyenler için fazla sıradan. The Snowman, neredeyse her açıdan sınıfta kalıyor. Bunun da en büyük nedeni, dediğim gibi filmin editlenmesinden kaynaklanıyor. Eğer bu filme karşı gerçekten ilgi duyuyorsanız, yazının bu bölümünü geçebilirsiniz çünkü gelecek paragraflar spoiler içerecek. Çünkü bu sorun hakkında spoiler vermeden konuşabileceğimi zannetmiyorum. [spoiler]Daha filmin ilk dakikalarında sahne geçişlerinin ne kadar acemi bir şekilde hazırlanmış olduğunu fark edebiliyorsunuz. Çünkü film çekilmeyen sahneleri sürekli gereksiz diyaloglarla doldurmaya başlıyor ve bir süreden sonra bundan bunalmaya başlıyorsunuz. Sırf bu yüzden film boyunca ana karakter Harry Hole'un (garip bir isim bu arada) kişiliği ve geçmişi hakkında hiçbir şey öğrenemiyoruz, hatta katilin amacını ve neden özellikle Harry'ye ipuçları bıraktığını anlayamıyoruz. Filmin sonunda katilin Harry'nin eski eşinin yeni kocası olduğunu görüyoruz ama yine de geçişliklerde o kadar çok kopukluk var ki, mesela neden katilin çocuklu aileleri hedefi olarak belirlediğini ve Harry'yi tuzağına çekmesi istemesini anlamıyoruz. Zaten film de olabilecek en saçma şekilde, katilin buzun üzerinde yürürken birdenbire suya düşmesi ve sudan çıkmak için hiçbir şekilde çaba göstermeyip ölmesiyle bitiyor. Bir de filmin temposundan bahsedelim. Kardan Adam Katili, film boyunca aşağı yukarı 4 defa harekete geçiyor. İlk defa katilin birisini öldürmesini görmek için 45. dakikaya, ikinci defa birisini öldürmesini görmek içinse 70. dakikaya kadar bekliyoruz. Üstelik bu sahneler de 18+ yaş sınırı almamak için öyle hafif geçiştirilmiş ki, her cinayet sahnesi çok zorlama bir şekilde filme alınmış gibi hissettiriyor. Üstelik son 5 dakikada Harry ile katil arasındaki ufak dövüş sahnesi, 13+ yaş sınırı almış bir filme ait gibiydi. Asıl sorun ise bu filmin 15+ yaş sınırı almış olması. Ayrıca film boyunca ortada gerçek bir tehlike, azalan bir süre bile yoktu. Katilin her işlediği cinayetten sonra ana karakterler film boyunca bunun hakkında konuşup sonucu hiçbir yere vardırmadan başka bir sahneye geçiyor, bu esnada da Val Kilmer gibi hikayeye hiçbir katkısı olmayan yardımcı karakterlerle tanışıyoruz. Bu arada ana karakterleri bir anlığına umursamadım, birisinin başına bir şey geldiği zaman Ay, umarım hayatta kalır.& yerine sürekli kendimi uyuklarken buldum. Sorun oyuncularda değildi ama bu karakterler öyle zayıf bir şekilde yazılmış ki, ortada onları umursamam için gerçek bir neden bile yoktu.[/spoiler] Kısacası, The Snowman'in harika bir sinematografisi, başarılı oyunculukları ve iyi bir yönetmenliği var ama bunları hiçbiri film üzerinde uygulanan editlenme tarzının acemiliğini geçiştirmiyor. Tıpkı geçen yılki Suicide Squad gibi, bu film de gereksiz derecede dağınıktı ve fragmanlarında gösterilen sahnelerden o kadar çoğu filmden çıkarılmış ki, çıkan sonucu bir film olarak göstermek sinema camiasına aykırı sayılır. Gerçi bu yıl çıkan Cumali Ceber gibi başından sonuna kadar kötü bir film değil The Snowman ama bu filmin içinde o kadar iyi ve umut verici şeyler var ki, çıkan sonucun hiçbir yere bağlanmadığını görmek büyük bir hayal kırıklığı yaratıyor. Eğer yakın gelecekte bu filme bir göz atmayı düşünürseniz, sakın düşünmeyin. Kötü bir filmden ziyade, tek kelimeyle bir vakit kaybı. FİLMİN İYİ YANLARI: + Yönetmen Tomas Alfredson'ın deniyor olması. + Başarılı oyunculuklar. + Sürükleyici bir ilk yarı... FİLMİN KÖTÜ YANLARI: - ...ama ilk yarıda anlatılan hiçbir şeyin bağlanmadığı ikinci yarı. - Birdenbire biten sonu. - Kötü editleme, umursamayacağınız karakterler, mantıksız sahneler. TOPLAM PUAN: 3.7/10\", 'label': 0}\n",
            "{'sentence': \"Kim ki-duk korenin Ahmet Uluçay'ıdır diyebilir miyiz?\", 'label': 1}\n",
            "{'sentence': 'çok güzel, çok eğlenceli,çok komik! harika bi film!!!! mutlaka ama mutlaka izleyin....benim için animasyondaki başyapıtlardan bi tanesi.', 'label': 1}\n",
            "{'sentence': 'Filmi sağolsunlar kaçak olarak izledim. İzlemez olaydım. Size şöyle söyleyeyim hayatımdan çalınmış 2.30 saati geri istiyorum. Filmi izlerken sürekli eee dedim ve bir şey olmasını, kişilerin bağlanmasını bekledim ama sonuç hüsran. Hele inal sahnesindeki çığlıkları duyarken içimden yönetmene sövdüm. Bu filmi izlemeye vereceğiniz para ile gidin sevdiklerinizi sevindirin çünkü o bileti alırsanız pişman olacaksınız.', 'label': 0}\n",
            "{'sentence': '1 yıldız fazla gelir bence filim in sonu başında gösterildi filmi anlamaya çalıştık korku sahnesi mi hiç korku titreme aksiyon yaşamadık arkadaşlarla. Bide koca sinemada 5 kişiydik millet niye gitmiyor dedik meğerse filim berbatmış. 5 arkadaşım da beğenmedi. Vaktimize yazık valla', 'label': 0}\n",
            "{'sentence': 'Sırf kan göstermek için çekilmiş iğrenç bi film.Nerdeyse her sahnede kan var ama işi çığrından çıkartmışlar.Hele o final sahnesi yokmu!Tamamıyla boşa vakit kaybı derim...', 'label': 0}\n",
            "{'sentence': \"Aktif bir tarih filmleri izleyicisi olarak gerçekten bu filmi çok beğendim. Oyunculuklar gerçekten harika, mekanlar ve kıyafetler harika. Resmen o dönemi size yansıtmayı başarabilmişler. Yaşanan olayın gerçek olması, dialoglar olsun çok hoşuma gitti. Özellikle churchill,hitler ve Atatürk'ün çok kısa canlandırılıp gösterilmesi çok yerinde olmuş. Atatürk'ü gördüğümde ağlayasım geldi bukadar güzel canlandırılmış. Bu konuda en iyisi oldugunu söyleyebilirim. Sadece İsmet İnönü canlandırması iyi olmamış. Tarihteki fotoğraflara baktığımızda İnönü'nün Churchill ile çok samimi görüntüleri var. Burda daha soğuk yansıtılmış. Film gerçekten mükemmel, şiddet ile tavsiye ederim. Bu alanda daha çok Türk yapımı film yapılmasını ümit ediyorum.\", 'label': 1}\n",
            "\n",
            "cola_train:\n",
            "{'sentence': 'Yapısal olarak virgül ile birbirlerine bağlanan iki cümle de şaşırtıcı yargı bildirmektedir.', 'label': 0}\n",
            "{'sentence': 'Tümceleri niteleyen belirteçler (maalesef, iyi ki, belki, açıkçası), genellikle konuşucunun yansıtır olay hakkında tutumunu.', 'label': 0}\n",
            "{'sentence': 'Birleşik sözcüklerin hecelenmesinde de heceler*in esas alınır.', 'label': 0}\n",
            "{'sentence': 'İnsanın ses aygıtı aslında herhangi bir doğal dilde bulunandan çok daha fazla sesi çıkarabilecek niteliktedir.', 'label': 1}\n",
            "{'sentence': 'Müzik dinlemek, doğayla iç içe olmak anlaşılma güçleşebilir.', 'label': 0}\n",
            "{'sentence': 'Bilhassa bizim gibi siyasi düşmanları çok olan milletler için, en buyuk dayanak vatani vicdan olabilir.', 'label': 0}\n",
            "{'sentence': 'Bu yazıda deyimlere kaynaklık eden çok sayıda fıkrayı gözler önüne getirmeye çalışacağız.', 'label': 1}\n",
            "{'sentence': 'XVI. yüzyılda Osmanlı Türkçesi olarak adlandırılan dönemde başlar.', 'label': 0}\n",
            "{'sentence': 'Göstergenin nedensəzlik denilen bu durum, dil bilimsel araştırmalarda en önemli ilkelerden biridir.', 'label': 0}\n",
            "{'sentence': 'Daha sonra r / sesi düşmüş ve kişi eki almaya başlamadı. 3. Tip Kişi Ekleri Gönüllülük kipinin çekiminde kullanılan eklerdir.', 'label': 0}\n",
            "\n",
            "cola_test:\n",
            "{'sentence': 'Eklerdeki biçim farkı, beraberinde bir anlam farkı getirmediğinden, bunlar ayrı biçimbirimler olamazlar.', 'label': 1}\n",
            "{'sentence': 'Türkçe, Anadoluda yazı bildikten sonra da zaman zaman ihmal edilmiş ve aydınların ilgisizliğine maruz kalmıştır.', 'label': 0}\n",
            "{'sentence': 'Yazıda Grek alfabesini ilk kullananlar hiç kuşkusuz Ortadoks Hristiyan inancına sahip olan Anadolulu Karamanlılar olmuştur.', 'label': 1}\n",
            "{'sentence': 'Unvan grubu olan bazı isimler kalıplaşarak yer ismi olabilir.', 'label': 1}\n",
            "{'sentence': 'En sonda ise sorunun muhatabı olan kişinin 2. tekil olduğunu gösteren bir sun eki bulunur.', 'label': 1}\n",
            "{'sentence': 'Bu uyarlama sırasında alıcı dil sözcüğün seslerindede kendi yapısal eğilimlerine uygun değişikliklere gider.', 'label': 0}\n",
            "{'sentence': 'Daha önce de geçtiği gibi Türkçede hece çekirdeğini ünlü oluşturur.', 'label': 1}\n",
            "{'sentence': 'Kültür, insan yığınıni millet haline getirir.', 'label': 0}\n",
            "{'sentence': 'Fiile eklenen işteşlik eki de işteşlik zamiri gibi farklı seviyelerde işteşlik ifadesi taşır.', 'label': 1}\n",
            "{'sentence': 'Bağımsız diller: Hint-Avrupa dillerinin Avrupadaki iki yalnız dili Arnavutça ve Yunancadır.', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "sst_train_len = len(sst2_train)\n",
        "sst_test_len = len(sst2_test)\n",
        "cola_train_len = len(cola_train)\n",
        "cola_test_len = len(cola_test)\n",
        "\n",
        "print(f\"SST2 eğitim kümesi uzunluğu: {sst_train_len}\")\n",
        "print(f\"SST2 test kümesi uzunluğu: {sst_test_len}\")\n",
        "print(f\"CoLA eğitim kümesi uzunluğu: {cola_train_len}\")\n",
        "print(f\"CoLA test kümesi uzunluğu: {cola_test_len}\")\n",
        "\n",
        "# sst2_train verisinin ilk 10 satırını yazdır\n",
        "print(\"sst2_train:\")\n",
        "for i in range(10):\n",
        "    print(sst2_train[i])\n",
        "\n",
        "# sst2_test verisinin ilk 10 satırını yazdır\n",
        "print(\"\\nsst2_test:\")\n",
        "for i in range(10):\n",
        "    print(sst2_test[i])\n",
        "\n",
        "# cola_train verisinin ilk 10 satırını yazdır\n",
        "print(\"\\ncola_train:\")\n",
        "for i in range(10):\n",
        "    print(cola_train[i])\n",
        "\n",
        "# cola_test verisinin ilk 10 satırını yazdır\n",
        "print(\"\\ncola_test:\")\n",
        "for i in range(10):\n",
        "    print(cola_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DxcVCVGuPcN"
      },
      "source": [
        "## Model installments\n",
        "\n",
        "1. https://huggingface.co/ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\n",
        "2. https://huggingface.co/KOCDIGITAL/Kocdigital-LLM-8b-v0.1\n",
        "3. https://huggingface.co/Trendyol/Llama-3-Trendyol-LLM-8b-chat-v2.0\n",
        "4. https://huggingface.co/TURKCELL/Turkcell-LLM-7b-v1\n",
        "5. https://huggingface.co/BrewInteractive/fikri-3.1-8B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "328569faae5243868e2a08421cbd2d98",
            "9ccd3c30760d45ef8369f83828b202d0",
            "2842c560a49d4be092810bb8c95f17d9",
            "d87e3051727e40ad98f5b9fcc3f0acd5",
            "6c9af1d088ee4d2c9ef2e8050e8834d4",
            "f0f97bfaace549a6a41deebcbb02cd4b",
            "51b4fb2bf77a4cd1bfa124f71913b919",
            "7679c9a38f074e66bfc18daff16a8fe5",
            "1bc5ded23b0043aa8d3ad7ff57d23e3e",
            "c00baf82aabb4a6faa3287f94dd09a5f",
            "9b218f86822d468880363311c0ea9b7f",
            "4ae49dd9afeb488d8a1febabf32bd87a",
            "3b743a48fdd74834b6c62b7f3fdac349",
            "f6027641f794437b951b34bf7dd1720b",
            "6c8e7d6568084c9db7f36ff2e2d43fb3",
            "b3d49acd34ea40b7ac1e52bdb67c2ff3",
            "07e991c7ea634239af083e1308894be1",
            "94bc607c43ad4c72bd3cd0342fa1f56e",
            "b7d6adc9a1c448259a8445f5a7c21d40",
            "d754c435c1e748669121dca6a7116f8f",
            "8a17ef059d5941d196e9eea5d6e3055f",
            "c031b50bf0714731b2e36764d0b393e5"
          ]
        },
        "id": "pCPXD8byuTEP",
        "outputId": "5d95e059-91c7-46a6-be17-8d8a886e1ec4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "328569faae5243868e2a08421cbd2d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ae49dd9afeb488d8a1febabf32bd87a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "def generate_llm (model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    return llm\n",
        "\n",
        "# Modelleri yükleme\n",
        "models = {\n",
        "    \"cosmos_dpo\": generate_llm(\"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\"),\n",
        "    #\"kocdigital_llm\": generate_llm(\"KOCDIGITAL/Kocdigital-LLM-8b-v0.1\"),\n",
        "    #\"trendyol_llm\": generate_llm(\"Trendyol/Trendyol-LLM-8b-chat-v2.0\"),\n",
        "    #\"turkcell_llm\":generate_llm(\"TURKCELL/Turkcell-LLM-7b-v1\"),\n",
        "    \"fikri_llm\": generate_llm(\"BrewInteractive/fikri-3.1-8B-Instruct\"),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompts_with_examples_sst2(sentence, shot_count):\n",
        "  prompt = f'Cümle: \"{sentence}\"\\nBu cümledeki duygu olumlu mu? Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\\n'\n",
        "  selected_examples = sst2_train.shuffle(seed=42).select(range(shot_count))\n",
        "  examples = \"\"\n",
        "  for i in range(shot_count):\n",
        "    cevap = \"\"\n",
        "    if(selected_examples[\"label\"][i] == 1):\n",
        "      cevap = \"Bu cümledeki duygu olumludur\"\n",
        "    else:\n",
        "      cevap = \"Bu cümledeki duygu olumsuzdur\"\n",
        "    examples += f'Cümle: \"{selected_examples[\"sentence\"][i]}\"\\nCevap: {cevap}\\n'\n",
        "\n",
        "  if (examples != \"\"):\n",
        "    examples += \"Yukarıdaki cümleleri ve cevaplarını değerlendir.\\n\"\n",
        "\n",
        "  return f\"{examples}{prompt}\"\n",
        "\n",
        "def build_prompts_with_examples_cola(sentence, shot_count):\n",
        "  prompt = f'Cümle: \"{sentence}\"\\nBu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\\n'\n",
        "  selected_examples = cola_train.shuffle(seed=42).select(range(shot_count))\n",
        "  examples = \"\"\n",
        "  for i in range(shot_count):\n",
        "    cevap = \"\"\n",
        "    if(selected_examples[\"label\"][i] == 1):\n",
        "      cevap = \"Bu cümle kurallara uygundur\"\n",
        "    else:\n",
        "      cevap = \"Bu cümle kurallara uygun değildir\"\n",
        "    examples += f'Cümle: \"{selected_examples[\"sentence\"][i]}\"\\nCevap: {cevap}\\n'\n",
        "\n",
        "  if (examples != \"\"):\n",
        "    examples += \"Yukarıdaki cümleleri ve cevaplarını değerlendir.\\n\"\n",
        "\n",
        "  return f\"{examples}{prompt}\"\n",
        "\n",
        "\n",
        "def run_prompt(prompt, model_name, max_new_tokens=150):\n",
        "  print(f\"Model: {model_name}\")\n",
        "  print(f\"Prompt: {prompt}\")\n",
        "  outputs = models[model_name](prompt, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "  generated = outputs[0]['generated_text'][len(prompt):].lower().strip()\n",
        "  return generated\n",
        "\n",
        "def run_bulk_prompt(prompts, model_name, max_new_tokens=150):\n",
        "  outputs = models[model_name](prompts, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "  generated_outputs = []\n",
        "  for output in outputs:\n",
        "    generated = output[0]['generated_text'][len(prompts[outputs.index(output)]):].lower().strip()  # İstem uzunluğunu çıkar\n",
        "    generated_outputs.append(generated)\n",
        "\n",
        "  return generated_outputs\n",
        "\n",
        "def bulk_predict_for_few_shot_sst2(sentences, shot_count, model_name, batch_size=5):\n",
        "  pred_labels = []\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    batch_sentences = sentences[i : i + batch_size] # Process sentences in batches\n",
        "    prompts = [build_prompts_with_examples_sst2(sentence, shot_count) for sentence in batch_sentences]\n",
        "    outputs = run_bulk_prompt(prompts, model_name)\n",
        "\n",
        "    for i, output in enumerate(outputs):\n",
        "      if \"evet\" in output:\n",
        "        pred_labels.append(1)\n",
        "      elif \"hayır\" in output:\n",
        "        pred_labels.append(0)\n",
        "      else:\n",
        "        pred_labels.append(-1)\n",
        "\n",
        "  return pred_labels\n",
        "\n",
        "def bulk_predict_for_few_shot_cola(sentences, shot_count, model_name, batch_size=5):\n",
        "  pred_labels = []\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "    batch_sentences = sentences[i : i + batch_size] # Process sentences in batches\n",
        "    prompts = [build_prompts_with_examples_cola(sentence, shot_count) for sentence in batch_sentences]\n",
        "    outputs = run_bulk_prompt(prompts, model_name)\n",
        "\n",
        "    for i, output in enumerate(outputs):\n",
        "      if \"evet\" in output:\n",
        "        pred_labels.append(1)\n",
        "      elif \"hayır\" in output:\n",
        "        pred_labels.append(0)\n",
        "      else:\n",
        "        pred_labels.append(-1)\n",
        "\n",
        "  return pred_labels"
      ],
      "metadata": {
        "id": "hDk3Olcp2pmu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sst2_test[\"sentence\"][:5])\n",
        "print(sst2_test[\"label\"][:5])\n",
        "\n",
        "print(sst2_test.select(range(3))[\"sentence\"])"
      ],
      "metadata": {
        "id": "lah514XlMRAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6df936-b338-492c-ef8b-340c2b288174"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!', 'İnsanın başına hiç beklemediği şeyler gelebilir gibi kısa ve klişe bir temayı filme biraz olsun anlam katmak için mi yaptılar ne...', \"Etkileyici bir kişilik Desmond Doss. Kesinlikle tarihe geçen bir hikayesi var. Mel Gibson bu gibi kahramanlık hikayelerini her zaman sevmiştir. Hacksaw Ridge&te de iyi iş çıkardığını söyleyebiliriz. Aslında izlerken pek çok mantık hatası var gibi gelse de, sonradan kısaca göz attığım tarihi gerçeklerde meğer olayların büyük oranda bu şekilde gerçekleşmiş olduğunu okudum. Uzun yıllar akılda kalıcı bir film mi? Pek sanmıyorum. Çünkü nedense o Er Ryan'ı Kurtarmak gibi bir hava yok maalesef filmde. Başlangıç bölümlerini biraz daha kısaltabilirlerdi. Garfield'ın oyunculuğu başarılı ancak kendisine ödül getirmeye yeterli mi, sanmıyorum. Filmin ikinci yarısı katıksız bir savaş filmi havasındayken, ilk yarısında pek bir hareket yok. Bunun bilinciyle izlemenizi öneririm.\", \"&Tinker Tailor Soldier Spy'ın yönetmeni Tomas Alfredson'ın yönettiği ve Martin Scorsese'nin yapımcılığını üstlendiği The Snowman'ın başrolünde son zamanların başarılı oyuncularından Michael Fassbender, Rebecca Ferguson ve J.K. Simmons var.& Başlı başına bu cümle ile ortaya hiç olmazsa ortalamanın üzerinde bir iş çıkması gerekir, değil mi? Ama maalesef The Snowman, bu tabirin yakınından bile geçemiyor. Hatta ortaya bu yılın kaçırılmış en büyük fırsatı çıkmış diyebilirim. İlk önce konuya değinelim. Filmin fragmanına göre The Snowman'in konusu şu: Son zamanlarda ortaya çıkıp insanları vahşetli bir şekilde öldüren Kardan Adam Katili'ni yakalamak için ünlü detektif Harry Hole ile meslektaşı Katrine Bratt, kendilerini oldukça tehlikeli bir gizemin içerisine bulurlar. Ve bu ikili katili bulmaya yaklaştıkça cinayetler artacak, durum ise içinden çıkılamaz bir hal alacaktır.& Öncelikle fragmanının anlatmaya çalıştığı konunun filmle alakasızlığını bırakın bir yana, bu fragmanın seyirciyi en çok yanıltacak yönü, The Snowman'i aşırı vahşetli bir korku filmi olarak gösteriyor oluşu herhalde. Çünkü film başlamadan önce arkamda oturan çiftlerden bir tanesi Eğer film fazla şiddetli gelecekse salondan hemen ayrılabiliriz gibi bir laf etti. Dürüst olmam gerekirse, ben de bu filmin ne kadar rahatsız edici olacağını bilmiyordum. Ama ortaya çıkan sonuçtan oldukça memnun kaldım çünkü bu film sayesinde 2 saat boyunca mışıl mışıl uyudum. Ama şaka bir yana The Snowman, muhtemelen şu an vizyonda oynayan en sıkıcı film sayılır. Neden mi? Çünkü bu filmde hiçbir şey yaşanmıyor da ondan! Aslında her ne kadar The Snowman'in ilk yarısı, tıpkı filmin geri kalanı gibi sadece diyaloglardan ibaret olsa da sürekli kendi kendime; Meraklanma, cevaplar yakında gelecek, yaşananlar en sonunda bir yere bağlanacak.& deyip durdum. Sonra film ikinci yarıya girdi. Ve film bittiğinde süre boyunca sorulan soruların hiçbirine cevap alamadığımı fark ettim, katilin kim olduğu dışında. Bu film Søren Sveistrup, Peter Straughan ile Hossein Amini gibi kuvvetli senaristler tarafından yazılmış. Fakat film stüdyosunun sürekli içeriğe karışması, filmin %15'lik bir diliminin çekilememesi, yönetmen ile senaryonun son anda değişikliğe uğraması ve hatta bir sürü sahnenin yeniden çekilmesiyle The Snowman, görüleceği üzere, büyük bir dağınıklıktan ibaret olmuş. Ve işin asıl acı veren tarafı bu filmde o kadar çok yetenek var ki, film bunların hiçbirini kullanmayı beceremiyor. Bu filmin de yaşadığı en büyük sıkıntı burada aslında. The Snowman harika manzaralara, başarılı bir yönetmene, güçlü oyunculuklara ve bazı yaratıcı fikirlere sahip olsa da ortaya çıkan sonuç o kadar dağınık olmuş ki, çıkan sonuç tek kelimeyle izlenemez bir hal almış. Aylar sonra bu film ev sinemasına gelip The Snowman'in DVD'sini rafta gördüğünüzde içinizden büyük ihtimalle şöyle bir düşünce geçecek: Vay be, oyuncu kadrosuna ve yönetmene bak hele! Gizem filmlerini sevdiğim için muhtemelen bu filmi de severim, bence eleştirmenler olayı fazla abartmış.& Ama filmi izlemiş birisi olarak size diyorum ki, bu filmi sakın izlemeyin. Biliyorum, film ekibi ile içerik hakkında o kadar yerden yere vurulacak bir şey yok. Hatta bu yıl izlediğim en kötü filmler arasında ilk 10'a gireceğinden bile şüpheliyim. Ama bu filmi öyle bir kırpmışlar ki, çıkan sonuç neresinden tutsan elinde kalıyor. Bir gizem filmi için fazla durağan, bir korku filmi için fazla kansız, sırf oyuncuların döktürmesini görmek isteyenler için fazla sıradan. The Snowman, neredeyse her açıdan sınıfta kalıyor. Bunun da en büyük nedeni, dediğim gibi filmin editlenmesinden kaynaklanıyor. Eğer bu filme karşı gerçekten ilgi duyuyorsanız, yazının bu bölümünü geçebilirsiniz çünkü gelecek paragraflar spoiler içerecek. Çünkü bu sorun hakkında spoiler vermeden konuşabileceğimi zannetmiyorum. [spoiler]Daha filmin ilk dakikalarında sahne geçişlerinin ne kadar acemi bir şekilde hazırlanmış olduğunu fark edebiliyorsunuz. Çünkü film çekilmeyen sahneleri sürekli gereksiz diyaloglarla doldurmaya başlıyor ve bir süreden sonra bundan bunalmaya başlıyorsunuz. Sırf bu yüzden film boyunca ana karakter Harry Hole'un (garip bir isim bu arada) kişiliği ve geçmişi hakkında hiçbir şey öğrenemiyoruz, hatta katilin amacını ve neden özellikle Harry'ye ipuçları bıraktığını anlayamıyoruz. Filmin sonunda katilin Harry'nin eski eşinin yeni kocası olduğunu görüyoruz ama yine de geçişliklerde o kadar çok kopukluk var ki, mesela neden katilin çocuklu aileleri hedefi olarak belirlediğini ve Harry'yi tuzağına çekmesi istemesini anlamıyoruz. Zaten film de olabilecek en saçma şekilde, katilin buzun üzerinde yürürken birdenbire suya düşmesi ve sudan çıkmak için hiçbir şekilde çaba göstermeyip ölmesiyle bitiyor. Bir de filmin temposundan bahsedelim. Kardan Adam Katili, film boyunca aşağı yukarı 4 defa harekete geçiyor. İlk defa katilin birisini öldürmesini görmek için 45. dakikaya, ikinci defa birisini öldürmesini görmek içinse 70. dakikaya kadar bekliyoruz. Üstelik bu sahneler de 18+ yaş sınırı almamak için öyle hafif geçiştirilmiş ki, her cinayet sahnesi çok zorlama bir şekilde filme alınmış gibi hissettiriyor. Üstelik son 5 dakikada Harry ile katil arasındaki ufak dövüş sahnesi, 13+ yaş sınırı almış bir filme ait gibiydi. Asıl sorun ise bu filmin 15+ yaş sınırı almış olması. Ayrıca film boyunca ortada gerçek bir tehlike, azalan bir süre bile yoktu. Katilin her işlediği cinayetten sonra ana karakterler film boyunca bunun hakkında konuşup sonucu hiçbir yere vardırmadan başka bir sahneye geçiyor, bu esnada da Val Kilmer gibi hikayeye hiçbir katkısı olmayan yardımcı karakterlerle tanışıyoruz. Bu arada ana karakterleri bir anlığına umursamadım, birisinin başına bir şey geldiği zaman Ay, umarım hayatta kalır.& yerine sürekli kendimi uyuklarken buldum. Sorun oyuncularda değildi ama bu karakterler öyle zayıf bir şekilde yazılmış ki, ortada onları umursamam için gerçek bir neden bile yoktu.[/spoiler] Kısacası, The Snowman'in harika bir sinematografisi, başarılı oyunculukları ve iyi bir yönetmenliği var ama bunları hiçbiri film üzerinde uygulanan editlenme tarzının acemiliğini geçiştirmiyor. Tıpkı geçen yılki Suicide Squad gibi, bu film de gereksiz derecede dağınıktı ve fragmanlarında gösterilen sahnelerden o kadar çoğu filmden çıkarılmış ki, çıkan sonucu bir film olarak göstermek sinema camiasına aykırı sayılır. Gerçi bu yıl çıkan Cumali Ceber gibi başından sonuna kadar kötü bir film değil The Snowman ama bu filmin içinde o kadar iyi ve umut verici şeyler var ki, çıkan sonucun hiçbir yere bağlanmadığını görmek büyük bir hayal kırıklığı yaratıyor. Eğer yakın gelecekte bu filme bir göz atmayı düşünürseniz, sakın düşünmeyin. Kötü bir filmden ziyade, tek kelimeyle bir vakit kaybı. FİLMİN İYİ YANLARI: + Yönetmen Tomas Alfredson'ın deniyor olması. + Başarılı oyunculuklar. + Sürükleyici bir ilk yarı... FİLMİN KÖTÜ YANLARI: - ...ama ilk yarıda anlatılan hiçbir şeyin bağlanmadığı ikinci yarı. - Birdenbire biten sonu. - Kötü editleme, umursamayacağınız karakterler, mantıksız sahneler. TOPLAM PUAN: 3.7/10\", \"Kim ki-duk korenin Ahmet Uluçay'ıdır diyebilir miyiz?\"]\n",
            "[0, 0, 1, 0, 1]\n",
            "['Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!', 'İnsanın başına hiç beklemediği şeyler gelebilir gibi kısa ve klişe bir temayı filme biraz olsun anlam katmak için mi yaptılar ne...', \"Etkileyici bir kişilik Desmond Doss. Kesinlikle tarihe geçen bir hikayesi var. Mel Gibson bu gibi kahramanlık hikayelerini her zaman sevmiştir. Hacksaw Ridge&te de iyi iş çıkardığını söyleyebiliriz. Aslında izlerken pek çok mantık hatası var gibi gelse de, sonradan kısaca göz attığım tarihi gerçeklerde meğer olayların büyük oranda bu şekilde gerçekleşmiş olduğunu okudum. Uzun yıllar akılda kalıcı bir film mi? Pek sanmıyorum. Çünkü nedense o Er Ryan'ı Kurtarmak gibi bir hava yok maalesef filmde. Başlangıç bölümlerini biraz daha kısaltabilirlerdi. Garfield'ın oyunculuğu başarılı ancak kendisine ödül getirmeye yeterli mi, sanmıyorum. Filmin ikinci yarısı katıksız bir savaş filmi havasındayken, ilk yarısında pek bir hareket yok. Bunun bilinciyle izlemenizi öneririm.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_prompt(build_prompts_with_examples_cola(cola_test[\"sentence\"][0],0), \"cosmos_dpo\"))"
      ],
      "metadata": {
        "id": "r7b6OD2k0WF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2a0b72-16fe-4637-ad9d-6038b5c24d43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: cosmos_dpo\n",
            "Prompt: Cümle: \"Eklerdeki biçim farkı, beraberinde bir anlam farkı getirmediğinden, bunlar ayrı biçimbirimler olamazlar.\"\n",
            "Bu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "evet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 0))\n",
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 3))\n",
        "print(build_prompts_with_examples_sst2(sst2_test[\"sentence\"][0], 5))\n",
        "\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 0))\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 3))\n",
        "print(build_prompts_with_examples_cola(cola_test[\"sentence\"][0], 5))"
      ],
      "metadata": {
        "id": "ZHX1Myulnc57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0a43f9-f5e7-40c9-d17a-3e9371950432"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cümle: \"Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!\"\n",
            "Bu cümledeki duygu olumlu mu? Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "Cümle: \"en sevdiğim animelerden biri.tabii ki de ilk film olması popüleritesini de arttırdı.çok keyifli ve etkileyici sahneleri vardı.mewtwo mükemmeldi. benimde en sevdiğim pokemonlar charizard ve feraligatr\"\n",
            "Cevap: Bu cümledeki duygu olumludur\n",
            "Cümle: \"The Theory of Everything ile birlikte 2014 yapımı izlediğim en iyi biyografik film. İngiltere de bile 1967 yılına kadar eşcinselliğin suç sayılması dünya savaşları kadar insanlık ayıbıdır.\"\n",
            "Cevap: Bu cümledeki duygu olumludur\n",
            "Cümle: \"1 yıldızı bile haketmiyor boşuna zaman kaybı arkadaşlar. Oyunculuk yok senaryo boş. Tek kelime ile rezalet\"\n",
            "Cevap: Bu cümledeki duygu olumsuzdur\n",
            "Yukarıdaki cümleleri ve cevaplarını değerlendir.\n",
            "Cümle: \"Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!\"\n",
            "Bu cümledeki duygu olumlu mu? Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "Cümle: \"en sevdiğim animelerden biri.tabii ki de ilk film olması popüleritesini de arttırdı.çok keyifli ve etkileyici sahneleri vardı.mewtwo mükemmeldi. benimde en sevdiğim pokemonlar charizard ve feraligatr\"\n",
            "Cevap: Bu cümledeki duygu olumludur\n",
            "Cümle: \"The Theory of Everything ile birlikte 2014 yapımı izlediğim en iyi biyografik film. İngiltere de bile 1967 yılına kadar eşcinselliğin suç sayılması dünya savaşları kadar insanlık ayıbıdır.\"\n",
            "Cevap: Bu cümledeki duygu olumludur\n",
            "Cümle: \"1 yıldızı bile haketmiyor boşuna zaman kaybı arkadaşlar. Oyunculuk yok senaryo boş. Tek kelime ile rezalet\"\n",
            "Cevap: Bu cümledeki duygu olumsuzdur\n",
            "Cümle: \"1.si bu porno fılm ve sadıstlık uzerıne kurulmus sanat sosu batırılmış anlamsız konusuz sıkıcı bır rezalite... resmen yatmak kalkmak uzerıne...koru gerılım yok sanat yok bılmem ne??? hayır ergenlıge yenı gırenler belkı bayılcak ama bu bır fılm degıl.. zaten cok ovulen fılmler hep berbat çıkar.. sınemada bunu kım ızler..resmen hersey meydanda. 1 verdım.......\"\n",
            "Cevap: Bu cümledeki duygu olumsuzdur\n",
            "Cümle: \"güzel bir animasyon.Oldukça eğlenceli,güldürüyor..Tavsiye ederim.\"\n",
            "Cevap: Bu cümledeki duygu olumludur\n",
            "Yukarıdaki cümleleri ve cevaplarını değerlendir.\n",
            "Cümle: \"Sene olmuş 2013, hala iki yaprak kıpırtısını korku filmi diye yutturmaya çalışanlar var. Efekt (ki film boyunca 1 veya 2 kez göreceksiniz) vasatın altında. Hikaye işe yaramaz, kurgu diye bir şey yok. E ne yapıyorsunuz, film çekiyoruz. Oldu!\"\n",
            "Bu cümledeki duygu olumlu mu? Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "Cümle: \"Eklerdeki biçim farkı, beraberinde bir anlam farkı getirmediğinden, bunlar ayrı biçimbirimler olamazlar.\"\n",
            "Bu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "Cümle: \"Şehitlik, dinlerimizde çok mühim ve ulaşılması zor bir mertebedir.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Cümle: \"Dünyanın en geniş profesyonel ağlarından birini oluşturan Linkedin, 2002 yılında kurulmuş, 2003 yılı açılmıştır.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Cümle: \"Ancak, anlamsal özellikleri bakımından sınıflandırmanın ortaya çıkardığı belirsizlik, adet gibi, eylemler için de geçerlidir.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Yukarıdaki cümleleri ve cevaplarını değerlendir.\n",
            "Cümle: \"Eklerdeki biçim farkı, beraberinde bir anlam farkı getirmediğinden, bunlar ayrı biçimbirimler olamazlar.\"\n",
            "Bu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n",
            "Cümle: \"Şehitlik, dinlerimizde çok mühim ve ulaşılması zor bir mertebedir.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Cümle: \"Dünyanın en geniş profesyonel ağlarından birini oluşturan Linkedin, 2002 yılında kurulmuş, 2003 yılı açılmıştır.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Cümle: \"Ancak, anlamsal özellikleri bakımından sınıflandırmanın ortaya çıkardığı belirsizlik, adet gibi, eylemler için de geçerlidir.\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Cümle: \"Bunları yapabilmek için ise belli birtakım bilgi ve tecrübelere sahip olması gerekir.\"\n",
            "Cevap: Bu cümle kurallara uygundur\n",
            "Cümle: \"Ama bu sözcük, söyleyişe göre bir emir cümlesi olabilirken gibi bir ad da olabilir: YAPma!, yapMA (eylemin adı)\"\n",
            "Cevap: Bu cümle kurallara uygun değildir\n",
            "Yukarıdaki cümleleri ve cevaplarını değerlendir.\n",
            "Cümle: \"Eklerdeki biçim farkı, beraberinde bir anlam farkı getirmediğinden, bunlar ayrı biçimbirimler olamazlar.\"\n",
            "Bu cümlenin Türkçe dilbilgisi kurallarına uygunluğunu değerlendirin. Eğer cümle dilbilgisi açısından kabul edilebilir ise, \"Evet\" değil ise \"Hayır\" şeklinde cevap verin.Lütfen sadece \"Evet\" veya \"Hayır\" şeklinde cevap verin.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = 10\n",
        "print(f\"Started for {sample_count} samples\")\n",
        "\n",
        "def run_analyse_for_sst2():\n",
        "  actual_labels_sst2 = sst2_test[\"label\"][:sample_count]\n",
        "  actual_labels_cola = cola_test[\"label\"][:sample_count]\n",
        "  print(f\"True Labels - sst-2: {actual_labels_sst2}\")\n",
        "  print(f\"True Labels - cola: {actual_labels_cola}\")\n",
        "\n",
        "  all_results = []\n",
        "\n",
        "  for model in models:\n",
        "    print(f\"Model: {model}\")\n",
        "\n",
        "    for shot in [0, 3, 5]:\n",
        "      print(f\"Shot: {shot}\")\n",
        "      print(f\"SST-2\")\n",
        "      predicted_labels_sst2 = bulk_predict_for_few_shot_sst2(sst2_test[\"sentence\"][:sample_count], shot_count=shot, model_name=model)\n",
        "\n",
        "      accuracy_sst2 = accuracy_score(actual_labels_sst2, predicted_labels_sst2)\n",
        "      f1_sst2 = f1_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "      precision_sst2 = precision_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "      recall_sst2 = recall_score(actual_labels_sst2, predicted_labels_sst2, average='weighted')\n",
        "\n",
        "      all_results.append({\n",
        "        \"model\": model,\n",
        "        \"task\": \"SST-2\",\n",
        "        \"shot\": shot,\n",
        "        \"accuracy\": accuracy_sst2,\n",
        "        \"f1\": f1_sst2,\n",
        "        \"precision\": precision_sst2,\n",
        "        \"recall\": recall_sst2\n",
        "      })\n",
        "\n",
        "      print(f\"CoLA\")\n",
        "      predicted_labels_cola = bulk_predict_for_few_shot_cola(cola_test[\"sentence\"][:sample_count], shot_count=shot, model_name=model)\n",
        "\n",
        "      accuracy_cola = accuracy_score(actual_labels_cola, predicted_labels_cola)\n",
        "      f1_cola = f1_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "      precision_cola = precision_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "      recall_cola = recall_score(actual_labels_cola, predicted_labels_cola, average='weighted')\n",
        "\n",
        "      all_results.append({\n",
        "        \"model\": model,\n",
        "        \"task\": \"CoLA\",\n",
        "        \"shot\": shot,\n",
        "        \"accuracy\": accuracy_cola,\n",
        "        \"f1\": f1_cola,\n",
        "        \"precision\": precision_cola,\n",
        "        \"recall\": recall_cola\n",
        "      })\n",
        "\n",
        "  return all_results\n",
        "\n",
        "\n",
        "results = run_analyse_for_sst2()\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nTüm sonuçlar:\")\n",
        "print(results_df)\n",
        "\n",
        "# Görselleştirme: Task ve shot sayısına göre doğruluk\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='model', y='accuracy', hue='shot',\n",
        "            data=results_df, palette='viridis',\n",
        "            dodge=True, ci=None)\n",
        "plt.title('LLM Modellerinin Görevlere Göre Doğruluk Performansı')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Shot Sayısı')\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_accuracy_by_shot.png')\n",
        "plt.show()\n",
        "\n",
        "# Task ve modele göre doğruluk karşılaştırması\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='task', y='accuracy', hue='model',\n",
        "            data=results_df, palette='Set2',\n",
        "            dodge=True, ci=None)\n",
        "plt.title('Görevlere Göre Model Doğruluk Karşılaştırması')\n",
        "plt.xlabel('Görev')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend(title='Model')\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_accuracy_by_model.png')\n",
        "plt.show()\n",
        "\n",
        "# Shot sayısının performans üzerindeki etkisi\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "for i, task in enumerate(['CoLA', 'SST-2']):\n",
        "    task_df = results_df[results_df['task'] == task]\n",
        "    sns.lineplot(x='shot', y='accuracy', hue='model',\n",
        "                 data=task_df, palette='Set1',\n",
        "                 markers=True, dashes=False, ax=axes[i])\n",
        "    axes[i].set_title(f'{task} Görevinde Shot Sayısının Etkisi')\n",
        "    axes[i].set_xlabel('Shot Sayısı')\n",
        "    axes[i].set_ylabel('Doğruluk')\n",
        "    axes[i].grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('shot_effect_on_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# 9. Sonuçların özeti\n",
        "# =============\n",
        "\n",
        "print(\"\\n=== ÖZET RAPOR ===\")\n",
        "\n",
        "# Görev ve model bazında en iyi performanslar\n",
        "for task in ['CoLA', 'SST-2']:\n",
        "    task_df = results_df[results_df['task'] == task]\n",
        "    best_model_idx = task_df['accuracy'].idxmax()\n",
        "    best_model = task_df.loc[best_model_idx]\n",
        "\n",
        "    print(f\"\\n{task} görevinde en iyi performans:\")\n",
        "    print(f\"Model: {best_model['model']}\")\n",
        "    print(f\"Shot Sayısı: {best_model['shot']}\")\n",
        "    print(f\"Doğruluk: {best_model['accuracy']:.4f}\")\n",
        "    print(f\"F1 Skor: {best_model['f1']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WM-0EvMLsJSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f423e9-8f82-4526-ed4b-0ef81ab31f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started for 10 samples\n",
            "True Labels - sst-2: [0, 0, 1, 0, 1, 1, 0, 0, 0, 1]\n",
            "True Labels - cola: [1, 0, 1, 1, 1, 0, 1, 0, 1, 1]\n",
            "Model: cosmos_dpo\n",
            "Shot: 0\n",
            "SST-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shot: 3\n",
            "SST-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shot: 5\n",
            "SST-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: fikri_llm\n",
            "Shot: 0\n",
            "SST-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shot: 3\n",
            "SST-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoLA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMJcoo19ptjuUejQ/UtkOB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "328569faae5243868e2a08421cbd2d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ccd3c30760d45ef8369f83828b202d0",
              "IPY_MODEL_2842c560a49d4be092810bb8c95f17d9",
              "IPY_MODEL_d87e3051727e40ad98f5b9fcc3f0acd5"
            ],
            "layout": "IPY_MODEL_6c9af1d088ee4d2c9ef2e8050e8834d4"
          }
        },
        "9ccd3c30760d45ef8369f83828b202d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f97bfaace549a6a41deebcbb02cd4b",
            "placeholder": "​",
            "style": "IPY_MODEL_51b4fb2bf77a4cd1bfa124f71913b919",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2842c560a49d4be092810bb8c95f17d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7679c9a38f074e66bfc18daff16a8fe5",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bc5ded23b0043aa8d3ad7ff57d23e3e",
            "value": 4
          }
        },
        "d87e3051727e40ad98f5b9fcc3f0acd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00baf82aabb4a6faa3287f94dd09a5f",
            "placeholder": "​",
            "style": "IPY_MODEL_9b218f86822d468880363311c0ea9b7f",
            "value": " 4/4 [00:09&lt;00:00,  2.19s/it]"
          }
        },
        "6c9af1d088ee4d2c9ef2e8050e8834d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f97bfaace549a6a41deebcbb02cd4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b4fb2bf77a4cd1bfa124f71913b919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7679c9a38f074e66bfc18daff16a8fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc5ded23b0043aa8d3ad7ff57d23e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c00baf82aabb4a6faa3287f94dd09a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b218f86822d468880363311c0ea9b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ae49dd9afeb488d8a1febabf32bd87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b743a48fdd74834b6c62b7f3fdac349",
              "IPY_MODEL_f6027641f794437b951b34bf7dd1720b",
              "IPY_MODEL_6c8e7d6568084c9db7f36ff2e2d43fb3"
            ],
            "layout": "IPY_MODEL_b3d49acd34ea40b7ac1e52bdb67c2ff3"
          }
        },
        "3b743a48fdd74834b6c62b7f3fdac349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e991c7ea634239af083e1308894be1",
            "placeholder": "​",
            "style": "IPY_MODEL_94bc607c43ad4c72bd3cd0342fa1f56e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f6027641f794437b951b34bf7dd1720b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d6adc9a1c448259a8445f5a7c21d40",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d754c435c1e748669121dca6a7116f8f",
            "value": 4
          }
        },
        "6c8e7d6568084c9db7f36ff2e2d43fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a17ef059d5941d196e9eea5d6e3055f",
            "placeholder": "​",
            "style": "IPY_MODEL_c031b50bf0714731b2e36764d0b393e5",
            "value": " 4/4 [01:30&lt;00:00, 19.25s/it]"
          }
        },
        "b3d49acd34ea40b7ac1e52bdb67c2ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e991c7ea634239af083e1308894be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94bc607c43ad4c72bd3cd0342fa1f56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d6adc9a1c448259a8445f5a7c21d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d754c435c1e748669121dca6a7116f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a17ef059d5941d196e9eea5d6e3055f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c031b50bf0714731b2e36764d0b393e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}